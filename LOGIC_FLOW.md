# ğŸ”„ Employee Query Bot - Logic Flow Diagram

## ğŸ“Š High-Level Architecture Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User Input    â”‚â”€â”€â”€â–¶â”‚  Streamlit UI    â”‚â”€â”€â”€â–¶â”‚  Session State  â”‚
â”‚   (Question)    â”‚    â”‚     (app.py)     â”‚    â”‚   Management    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                        â”‚
                                â–¼                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Document      â”‚â—„â”€â”€â”€â”‚  Document Loader â”‚    â”‚  Vector Store   â”‚
â”‚   Processing    â”‚    â”‚   (loader.py)    â”‚    â”‚     (FAISS)     â”‚
â”‚   (PDF/TXT)     â”‚    â”‚                  â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                        â”‚
                                â–¼                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   OpenAI API    â”‚â—„â”€â”€â”€â”‚   Query Bot      â”‚â—„â”€â”€â”€â”‚   Retriever     â”‚
â”‚   (LLM Chain)   â”‚    â”‚ (query_bot.py)   â”‚    â”‚   (Similarity   â”‚
â”‚                 â”‚    â”‚                  â”‚    â”‚     Search)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚   AI Response    â”‚
                        â”‚   + Token Info   â”‚
                        â”‚                  â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Detailed Application Flow

### **1. Application Initialization**
```
START
  â”‚
  â”œâ”€ Load Environment Variables (.env)
  â”‚   â””â”€ OPENAI_API_KEY
  â”‚
  â”œâ”€ Initialize Streamlit Page Config
  â”‚   â”œâ”€ Title: "ğŸ’¬ HR FAQ Chatbot"
  â”‚   â””â”€ Layout: "centered"
  â”‚
  â”œâ”€ Initialize Session State
  â”‚   â”œâ”€ chat_history = []
  â”‚   â””â”€ qa_chain = None
  â”‚
  â””â”€ Check if qa_chain exists
      â”œâ”€ NO: Go to Document Loading
      â””â”€ YES: Go to Chat Interface
```

### **2. Document Loading & Processing**
```
DOCUMENT LOADING
  â”‚
  â”œâ”€ Scan data/ folder
  â”‚   â”œâ”€ Find PDF files
  â”‚   â””â”€ Find TXT files
  â”‚
  â”œâ”€ For each document:
  â”‚   â”œâ”€ Load document content
  â”‚   â”‚   â”œâ”€ PDF: PyPDFLoader
  â”‚   â”‚   â””â”€ TXT: TextLoader
  â”‚   â”‚
  â”‚   â”œâ”€ Split into chunks
  â”‚   â”‚   â”œâ”€ chunk_size: 1000
  â”‚   â”‚   â””â”€ chunk_overlap: 100
  â”‚   â”‚
  â”‚   â””â”€ Add to docs list
  â”‚
  â”œâ”€ Create embeddings (OpenAI)
  â”‚
  â”œâ”€ Build FAISS vector store
  â”‚
  â”œâ”€ Create conversational chain
  â”‚   â”œâ”€ LLM: ChatOpenAI (temperature=0)
  â”‚   â”œâ”€ Retriever: vectorstore.as_retriever()
  â”‚   â””â”€ Prompt: HR Assistant template
  â”‚
  â””â”€ Store qa_chain in session_state
```

### **3. Chat Interface Flow**
```
CHAT INTERFACE
  â”‚
  â”œâ”€ Display Chat History
  â”‚   â””â”€ Show previous messages
  â”‚
  â”œâ”€ Wait for User Input
  â”‚   â””â”€ chat_input: "Ask your HR question here..."
  â”‚
  â”œâ”€ User submits question
  â”‚   â”‚
  â”‚   â”œâ”€ Add user message to chat_history
  â”‚   â”‚
  â”‚   â”œâ”€ Process with QA Chain
  â”‚   â”‚   â”œâ”€ Input: user question + chat history
  â”‚   â”‚   â”œâ”€ Retrieve relevant documents
  â”‚   â”‚   â”œâ”€ Generate context from documents
  â”‚   â”‚   â”œâ”€ Send to OpenAI with prompt
  â”‚   â”‚   â””â”€ Get AI response
  â”‚   â”‚
  â”‚   â”œâ”€ Track token usage
  â”‚   â”‚   â”œâ”€ Prompt tokens
  â”‚   â”‚   â”œâ”€ Completion tokens
  â”‚   â”‚   â”œâ”€ Total tokens
  â”‚   â”‚   â””â”€ Estimated cost
  â”‚   â”‚
  â”‚   â”œâ”€ Display AI response
  â”‚   â”‚
  â”‚   â”œâ”€ Add response to chat_history
  â”‚   â”‚
  â”‚   â””â”€ Show token usage statistics
  â”‚
  â””â”€ Loop back to wait for next input
```

## ğŸ”§ Component Breakdown

### **app.py (Main Interface)**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           app.py                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Streamlit UI setup            â”‚
â”‚ â€¢ Session state management      â”‚
â”‚ â€¢ Chat interface rendering      â”‚
â”‚ â€¢ Token usage tracking          â”‚
â”‚ â€¢ Reset functionality           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **loader.py (Document Processing)**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          loader.py              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ load_documents_from_folder()  â”‚
â”‚   â”œâ”€ PDF processing             â”‚
â”‚   â”œâ”€ TXT processing             â”‚
â”‚   â””â”€ Document chunking          â”‚
â”‚                                 â”‚
â”‚ â€¢ create_vector_store()         â”‚
â”‚   â”œâ”€ OpenAI embeddings          â”‚
â”‚   â””â”€ FAISS vector database      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **query_bot.py (AI Chain)**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         query_bot.py            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ get_conversational_chain()    â”‚
â”‚   â”œâ”€ ChatOpenAI LLM             â”‚
â”‚   â”œâ”€ Custom HR prompt template  â”‚
â”‚   â”œâ”€ ConversationalRetrieval    â”‚
â”‚   â””â”€ Source document return     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Data Flow Sequence

### **Step-by-Step Processing**
1. **User Question** â†’ Streamlit Chat Input
2. **Question Processing** â†’ Add to chat history
3. **Document Retrieval** â†’ FAISS similarity search
4. **Context Building** â†’ Relevant document chunks
5. **LLM Processing** â†’ OpenAI API call with context
6. **Response Generation** â†’ AI answer based on documents
7. **Token Tracking** â†’ Usage statistics calculation
8. **Display Results** â†’ Show answer + token info
9. **State Update** â†’ Add to conversation history

## ğŸ¯ Key Decision Points

### **Document Loading Logic**
```
IF qa_chain is None:
    â”œâ”€ Load documents from data/ folder
    â”œâ”€ Create vector embeddings
    â”œâ”€ Initialize conversational chain
    â””â”€ Display "Documents loaded!"
ELSE:
    â””â”€ Proceed to chat interface
```

### **Question Processing Logic**
```
IF user submits question:
    â”œâ”€ Add question to chat history
    â”œâ”€ Invoke QA chain with:
    â”‚   â”œâ”€ Current question
    â”‚   â””â”€ Previous chat history
    â”œâ”€ Get response + token usage
    â”œâ”€ Display response
    â””â”€ Update chat history
ELSE:
    â””â”€ Wait for user input
```

### **Error Handling**
```
TRY:
    â”œâ”€ Load each document
    â”œâ”€ Process embeddings
    â””â”€ Generate response
CATCH:
    â”œâ”€ Log error message
    â”œâ”€ Continue with other documents
    â””â”€ Display user-friendly error
```

## ğŸ“Š Performance Considerations

### **Optimization Points**
- **One-time Loading**: Documents loaded only once per session
- **Session Persistence**: Vector store cached in session state
- **Chunked Processing**: Large documents split for better retrieval
- **Efficient Search**: FAISS for fast similarity matching
- **Token Tracking**: Real-time cost monitoring

### **Memory Management**
- Documents processed in chunks
- Vector store stored in session state
- Chat history maintained in memory
- Automatic cleanup on reset

---

## ğŸ”„ Reset Flow
```
User clicks "ğŸ”„ Reset Chat"
  â”‚
  â”œâ”€ Clear chat_history = []
  â”œâ”€ Set qa_chain = None
  â”œâ”€ Trigger app rerun
  â””â”€ Return to document loading phase
```

This flow diagram shows how your Employee Query Bot processes documents, manages conversations, and provides intelligent responses based on your HR policy documents!
